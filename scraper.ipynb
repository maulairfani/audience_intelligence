{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "api_key = \"AIzaSyCI0cHHN4dD1D5VVmqIM-igV-Lq0Rpt2j0\"\n",
    "youtube = build('youtube', 'v3',developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terdapat 31 video pada playlist\n"
     ]
    }
   ],
   "source": [
    "# Ambil semua judul dalam playlist\n",
    "request = youtube.playlistItems().list(\n",
    "    part=\"snippet\",\n",
    "    playlistId=\"PLkiSnq8pdz9T3QQVbczz4XVgsHjjJK3vd\", # Playlist id bocor alus,\n",
    "    maxResults=50\n",
    ")\n",
    "playlist = request.execute()\n",
    "playlist_items = playlist[\"items\"]\n",
    "print(f\"Terdapat {len(playlist_items)} video pada playlist\")\n",
    "\n",
    "# Ambil video id\n",
    "video_ids = list()\n",
    "for item in playlist_items:\n",
    "    video_ids.append(item[\"snippet\"][\"resourceId\"][\"videoId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:01<00:00, 16.80it/s]\n"
     ]
    }
   ],
   "source": [
    "data = dict()\n",
    "for i in tqdm(range(len(video_ids))):\n",
    "    request = youtube.videos().list(\n",
    "        part=\"contentDetails,id,liveStreamingDetails,localizations,player,recordingDetails,snippet,statistics,status,topicDetails\",\n",
    "        id=video_ids[i]\n",
    "    )\n",
    "    response = request.execute()\n",
    "    data[video_ids[i]] = response\n",
    "\n",
    "with open(\"data.json\", \"w\") as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SQXcaHsG0Fc', 'mBPb_ZWSsSU', 'iyhepYA0qU8', 'Yxxap3815IM', '-7-DT39jnas', 'sUdAvJ0lUHQ', 'z30vDjd1s3U', 'DhjzluWJXKY', 'CUpC_08jbUU', 'oovSMZlzA3o', 'jlmBvgvhBfQ', '5AMf9MqnYNE', 'Nv56vD2XLbw', 'aV0YFRu3sVQ', 'uqoVC5BISlA', 'Vvl_Nd_S-Ng', 'Toz5-ZFVO9s', 'oChmn56mgOc', 'xOqt_WNOhxQ', 'CcB6QnYPR3s', 'ED4tTy8bDGk', '-u4THO6xOt0', 'w-lphu4KdcY', 'mT42kKwceeU', 'xs6AL3xfpFU', 'ufnRKFihJ9M', 'xTSABfhXFFI', 'D_LmGMCnih0', 'Xjekfmg70wI', 'zKVC0y0CoGw', 'YOJ9L4M9Mgo'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data.json\") as file:\n",
    "    d = json.load(file)\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langsung scraping setiap video yang ada di playlist, outputnya jadi satu csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTopLevelCommentReplies(topCommentId, token): \n",
    "  \"\"\"\n",
    "  Recursive function that retrieves the replies a given comment has.\n",
    "  \"\"\"\n",
    "\n",
    "  replies_response=youtube.comments().list(part='snippet',maxResults=100,parentId=topCommentId,pageToken=token).execute()\n",
    "\n",
    "  for indx, reply in enumerate(replies_response['items']):\n",
    "    all_comments.append(reply['snippet']['textDisplay'])\n",
    "    \n",
    "  if \"nextPageToken\" in replies_response: \n",
    "    return getAllTopLevelCommentReplies(topCommentId, replies_response['nextPageToken'])\n",
    "  else:\n",
    "    return []\n",
    "      \n",
    "def get_comments(youtube, video_id, token): \n",
    "  \"\"\"\n",
    "  Recursive function that retrieves the comments (top-level ones) a given video has.\n",
    "  \"\"\"\n",
    "\n",
    "  global all_comments\n",
    "  global all_authors\n",
    "  totalReplyCount = 0\n",
    "  token_reply = None\n",
    "\n",
    "  if (len(token.strip()) == 0): \n",
    "    all_comments = []\n",
    "\n",
    "  if (token == ''): \n",
    "    video_response=youtube.commentThreads().list(part='snippet',maxResults=100,videoId=video_id,order='relevance').execute() \n",
    "  else: \n",
    "    video_response=youtube.commentThreads().list(part='snippet',maxResults=100,videoId=video_id,order='relevance',pageToken=token).execute() \n",
    "\n",
    "  # Loop comments from the video: \n",
    "  for indx, item in enumerate(video_response['items']): \n",
    "    # Append coments:\n",
    "    all_comments.append(\"COMMENT WITH \" + str(item['snippet']['totalReplyCount']) + \" replies: \" + item['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "    all_authors.append(item['snippet']['topLevelComment']['snippet']['authorDisplayName'])\n",
    "    # Get total reply count: \n",
    "    totalReplyCount = item['snippet']['totalReplyCount']\n",
    "\n",
    "    # If the comment has replies, get them:\n",
    "    if (totalReplyCount > 0): \n",
    "      # Get replies - first batch: \n",
    "      replies_response=youtube.comments().list(part='snippet',maxResults=100,parentId=item['id']).execute()\n",
    "      for indx, reply in enumerate(replies_response['items']):\n",
    "        # Append the replies to the main array: \n",
    "        all_comments.append((\" \"*2) + \"=>FIRST CALLBACK REPLY: \" + reply['snippet']['textDisplay'])\n",
    "        all_authors.append(reply['snippet']['authorDisplayName'])\n",
    "\n",
    "      # If the reply has a token for get more replies, loop those replies \n",
    "      # and add those replies to the main array: \n",
    "      while \"nextPageToken\" in replies_response:\n",
    "        token_reply = replies_response['nextPageToken']\n",
    "        replies_response=youtube.comments().list(part='snippet',maxResults=100,parentId=item['id'],pageToken=token_reply).execute()\n",
    "        for indx, reply in enumerate(replies_response['items']):\n",
    "          all_comments.append((\" \"*4) + \"==>WHILE GETTING REPLIES: \" + reply['snippet']['textDisplay'])\n",
    "          all_authors.append(reply['snippet']['authorDisplayName'])\n",
    "    \n",
    "  # Check if the video_response has more comments:\n",
    "  if \"nextPageToken\" in video_response: \n",
    "    return get_comments(youtube, video_id, video_response['nextPageToken']) \n",
    "  else: \n",
    "    # Remove empty elements added to the list \"due to the return in both functions\":\n",
    "    all_comments = [x for x in all_comments if len(x) > 0]\n",
    "    # print(\"Fin\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:11<00:00, 35.54s/it]\n"
     ]
    }
   ],
   "source": [
    "# Proses scraping\n",
    "df_comments = pd.DataFrame(columns=[\"video_id\", \"author\", \"comment\"])\n",
    "for i in tqdm(range(len(video_ids))):\n",
    "    all_comments=[]\n",
    "    all_authors=[]\n",
    "    qtyReplies = 0\n",
    "    qtyMainComments = 0\n",
    "\n",
    "    result = get_comments(youtube, video_ids[i], '')\n",
    "\n",
    "    temp = pd.DataFrame({\n",
    "        \"video_id\": [video_ids[i]] * len(all_comments),\n",
    "        \"comment\": all_comments,\n",
    "        \"author\": all_authors\n",
    "    })\n",
    "    df_comments = df_comments.append(temp, ignore_index=True)\n",
    "\n",
    "    df_comments.to_csv(\"all_comments.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
